model_settings:
  pretrained_model: 'distilbert-base-uncased'
  num_labels: 2

training_args:
  output_dir: './results'
  num_train_epochs: 1
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  warmup_steps: 50
  weight_decay: 0.01
  logging_dir: './logs'
  logging_steps: 50

general_args:
  path_train_data: "full_data/train_dataset_tokenized"
  path_val_data: "full_data/val_dataset_tokenized"
  path_test_data: "full_data/test_dataset_tokenized"
  wandb_enabled: "True"

gcp_args:
  model_name: 'experiment_1'
  gcs_bucket: 'ai-detection-bucket'
  gcs_path: 'models'
  push_model_to_gcs : "True"
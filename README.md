# MLOps DTU Course 02476 - Detecting AI Generated Text 

##### Students: 
Christian Raasteen s204148 - Christoffer Wejendorp s204090 - Jasmin Thari s204155 - Johanne Franck s204088

##### Goal of project: 
The goal of the project is to use natural language processing to solve a binary classification task to detecting whether a text is AI generated or not.

##### Framework: 
As we are working with NLP, we will use the [Transformers framework](https://github.com/huggingface/transformers) from the Huggingface group. As a starting point we intend to use one of the many pretrained models in the Framework on our data and then further improve the model performance.

##### Data:  
We will be using the [data set](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/data) that consists of 1375 esssays written by students. They are sorted into two topics: "Car-free cities" and "Does the electoral college work?" and are written in response to a prompt. We augment the data set with 1375 essays generated by the openAI API. The essays are written in response to the same prompts as the student essays. The data set can then be split into a training and test set as desired.

The provided data set is a csv file with 2750 rows and 4 columns.
Each row in the dataset contains:

* id - A unique identifier for each essay.
* prompt_id - Identifies the prompt the essay was written in response to.
* text - The essay text itself.
* generated - Whether the essay was written by a student (0) or generated by the openAI API (1).

##### Model: 
We will be using a pre-trained [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) model (present in the Transformers library for Huggingface) for the NLP classification task. DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.

##### Checklist
In this project we focus on keeping a good project structure and make our project reproducible. In order to obtain this, we will utilize tools as cookiecutter for organised document structure, docker for reproducibility as well as dvc for data handling (even though the data size is small).  

Please see the [checklist.md](https://github.com/ChrisRawstone/Detecting_AI_Generated_Text/blob/develop/checklist.md) for what learning objectives the project fulfills. 

## Project structure

The directory structure of the project looks like this:

```txt

├── Makefile             <- Makefile with convenience commands like `make data` or `make train`
├── README.md            <- The top-level README for developers using this project.
├── data
│   ├── processed        <- The final, canonical data sets for modeling.
│   └── raw              <- The original, immutable data dump.
│
├── docs                 <- Documentation folder
│   │
│   ├── index.md         <- Homepage for your documentation
│   │
│   ├── mkdocs.yml       <- Configuration file for mkdocs
│   │
│   └── source/          <- Source directory for documentation files
│
├── models               <- Trained and serialized models, model predictions, or model summaries
│
├── notebooks            <- Jupyter notebooks.
│
├── pyproject.toml       <- Project configuration file
│
├── reports              <- Generated analysis as HTML, PDF, LaTeX, etc.
│   └── figures          <- Generated graphics and figures to be used in reporting
│
├── requirements.txt     <- The requirements file for reproducing the analysis environment
|
├── requirements_dev.txt <- The requirements file for reproducing the analysis environment
│
├── tests                <- Test files
│
├── src  <- Source code for use in this project.
│   │
│   ├── __init__.py      <- Makes folder a Python module
│   │
│   ├── data             <- Scripts to download or generate data
│   │   ├── __init__.py
│   │   └── make_dataset.py
│   │
│   ├── models           <- model implementations, training script and prediction script
│   │   ├── __init__.py
│   │   ├── model.py
│   │
│   ├── visualization    <- Scripts to create exploratory and results oriented visualizations
│   │   ├── __init__.py
│   │   └── visualize.py
│   ├── train_model.py   <- script for training the model
│   └── predict_model.py <- script for predicting from a model
│
└── LICENSE              <- Open-source license if one is chosen
```

Created using [mlops_template](https://github.com/SkafteNicki/mlops_template),
a [cookiecutter template](https://github.com/cookiecutter/cookiecutter) for getting
started with Machine Learning Operations (MLOps).
